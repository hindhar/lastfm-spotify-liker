Directory Structure:
====================

lastfm-spotify-liker/
    .DS_Store
    requirements.txt
    codebase.py
    README.md
    codebase.txt
    .gitignore
    .env
    main.py
    .cache
    playlist_id.txt
    logs/
        album_saver.log
        hot_100_playlist.log
        .gitignore
        lastfm_spotify_liker.log
        main.log
    db/
        lastfm_history.db
        spotify_liked_songs.db
        .gitignore
        album_saver.db
    .vscode/
        settings.json
    src/
        .DS_Store
        database.py
        __init__.py
        utils.py
        spotify_operations.py
        scripts/
            album_saver.py
            spotify_deduplicator.py
            .DS_Store
            __init__.py
            lastfm_spotify_liker.py
            remove_duplicate_albums.py
            hot_100_playlist.py


File Contents:
==============

File: requirements.txt
======================

certifi==2024.8.30
charset-normalizer==3.4.0
fuzzywuzzy==0.18.0
idna==3.10
Levenshtein==0.26.0
python-dotenv==1.0.1
python-Levenshtein==0.26.0
RapidFuzz==3.10.0
redis==5.1.1
requests==2.32.3
spotipy==2.24.0
urllib3==2.2.3


File: README.md
===============



File: main.py
=============

import os
import sys
import subprocess
import logging
from datetime import datetime, timezone

# Add the project root to the Python path
project_root = os.path.abspath(os.path.dirname(__file__))
sys.path.insert(0, project_root)

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    filename='logs/main.log',
    filemode='a'
)

def run_script(script_name):
    script_path = os.path.join(project_root, 'src', 'scripts', script_name)
    logging.info(f"Running {script_name}")
    try:
        subprocess.run([sys.executable, script_path], check=True)
        logging.info(f"{script_name} completed successfully")
    except subprocess.CalledProcessError as e:
        logging.error(f"Error running {script_name}: {e}")

def main():
    logging.info(f"Starting main process at {datetime.utcnow().replace(tzinfo=timezone.utc).isoformat()}")
    
    # Run lastfm_spotify_liker.py
    run_script('lastfm_spotify_liker.py')
    
    # Run album_saver.py
    run_script('album_saver.py')
    
    # Run hot_100_playlist.py
    run_script('hot_100_playlist.py')
    
    logging.info(f"Main process completed at {datetime.utcnow().replace(tzinfo=timezone.utc).isoformat()}")

if __name__ == "__main__":
    main()


File: playlist_id.txt
=====================

5iFg7DdS2m8XV8kmQqg4SU

File: db/lastfm_history.db
==========================

Error reading file: 'utf-8' codec can't decode byte 0xb0 in position 26: invalid start byte


File: db/spotify_liked_songs.db
===============================

Error reading file: 'utf-8' codec can't decode byte 0xe8 in position 31: invalid continuation byte


File: db/album_saver.db
=======================

Error reading file: 'utf-8' codec can't decode byte 0xd0 in position 99: invalid continuation byte


File: src/database.py
=====================

# database.py

import sqlite3
import logging
from datetime import datetime, timezone
from src.utils import normalize_string
from typing import List, Dict, Optional

class Database:
    def __init__(self, db_file: str = 'db/lastfm_history.db'):
        """Initialize the Database class."""
        self.db_file = db_file
        self.create_table()
        self.add_processed_column()  # Add this line to ensure the 'processed' column exists

    def connect(self) -> sqlite3.Connection:
        """Connect to the SQLite database."""
        return sqlite3.connect(self.db_file)

    def create_table(self) -> None:
        """Create the tracks table in the database if it doesn't exist."""
        with self.connect() as conn:
            c = conn.cursor()
            c.execute('''
                CREATE TABLE IF NOT EXISTS tracks (
                    id INTEGER PRIMARY KEY,
                    artist TEXT,
                    name TEXT,
                    album TEXT,
                    listen_count INTEGER,
                    last_listened DATETIME,
                    mbid TEXT,
                    processed BOOLEAN DEFAULT 0,
                    UNIQUE(artist, name)
                )
            ''')
            conn.commit()
        logging.info("Initialized tracks table in Last.fm database.")

    def add_or_update_track(self, track: Dict) -> None:
        """Add a new track or update an existing track in the database."""
        artist = normalize_string(track['artist'])
        name = normalize_string(track['name'])
        album = normalize_string(track.get('album', ''))
        date = track['date'].astimezone(timezone.utc).isoformat()
        query = '''
        INSERT INTO tracks (artist, name, album, listen_count, last_listened, mbid)
        VALUES (?, ?, ?, 1, ?, ?)
        ON CONFLICT(artist, name) DO UPDATE SET
        listen_count = listen_count + 1,
        last_listened = ?,
        album = COALESCE(?, album),
        mbid = COALESCE(?, mbid)
        '''
        with self.connect() as conn:
            conn.execute(query, (
                artist,
                name,
                album,
                date,
                track.get('mbid', ''),
                date,
                album,
                track.get('mbid', '')
            ))
        logging.info(f"Added/Updated track in database: {artist} - {name}")

    def get_last_update_time(self) -> Optional[datetime]:
        """Get the last time a track was listened to."""
        query = 'SELECT MAX(last_listened) FROM tracks'
        with self.connect() as conn:
            result = conn.execute(query).fetchone()
        if result and result[0]:
            return datetime.fromisoformat(result[0]).replace(tzinfo=timezone.utc)
        return None

    def get_frequently_played_tracks(self, min_count: int = 5) -> List[tuple]:
        """Get tracks that have been played frequently."""
        query = '''
        SELECT artist, name, listen_count
        FROM tracks
        WHERE listen_count >= ? AND processed = 0
        ORDER BY listen_count DESC
        '''
        with self.connect() as conn:
            return conn.execute(query, (min_count,)).fetchall()

    def mark_tracks_as_processed(self, tracks: List[tuple]) -> None:
        """Mark tracks as processed."""
        with self.connect() as conn:
            c = conn.cursor()
            for artist, name, _ in tracks:
                c.execute('''
                    UPDATE tracks
                    SET processed = 1
                    WHERE artist = ? AND name = ?
                ''', (artist, name))
            conn.commit()
        logging.info(f"Marked {len(tracks)} tracks as processed.")

    def get_albums_since(self, last_update: datetime) -> List[Dict]:
        """Retrieve all albums listened to since the last update."""
        query = """
        SELECT DISTINCT album, artist 
        FROM tracks 
        WHERE last_listened > ?
        """
        with self.connect() as conn:
            c = conn.cursor()
            c.execute(query, (last_update.isoformat(),))
            albums = [{'name': row[0], 'artist': row[1]} for row in c.fetchall()]
        logging.info(f"Retrieved {len(albums)} albums since last update.")
        return albums

    def get_all_albums(self) -> List[Dict]:
        """Retrieve all unique albums from the tracks table."""
        query = "SELECT DISTINCT album, artist FROM tracks"
        with self.connect() as conn:
            c = conn.cursor()
            c.execute(query)
            albums = [{'name': row[0], 'artist': row[1]} for row in c.fetchall()]
        logging.info(f"Retrieved all albums from the Last.fm database: {len(albums)} albums.")
        return albums

    def add_processed_column(self) -> None:
        """Add the 'processed' column to the tracks table if it doesn't exist."""
        with self.connect() as conn:
            c = conn.cursor()
            try:
                c.execute('ALTER TABLE tracks ADD COLUMN processed BOOLEAN DEFAULT 0')
                conn.commit()
                logging.info("Added 'processed' column to tracks table.")
            except sqlite3.OperationalError as e:
                if "duplicate column name" in str(e):
                    logging.info("'processed' column already exists in tracks table.")
                else:
                    logging.error(f"Error adding 'processed' column: {e}", exc_info=True)
                    raise


File: src/__init__.py
=====================



File: src/utils.py
==================

# utils.py

import re
import threading
import sys
import time
from datetime import datetime, timezone

def normalize_string(s: str) -> str:
    """Normalize a string for consistent comparison."""
    s = s.lower().strip()
    # Remove content in parentheses or brackets
    s = re.sub(r'\s*[\(\[\{].*?[\)\]\}]', '', s)
    # Remove version-specific keywords and their accompanying years if any
    s = re.sub(r'\b(remastered|live|acoustic|mono|stereo|version|edit|feat\.?|featuring|from|remix)\b(\s+\d{4})?', '', s)
    # Remove extra punctuation (but keep numbers)
    s = re.sub(r'[^a-zA-Z0-9\s]', '', s)
    # Remove extra whitespace
    s = re.sub(r'\s+', ' ', s)
    return s.strip()

def get_user_input_with_timeout(prompt: str, timeout: int = 10) -> str:
    """Get user input with a timeout."""
    print(prompt, end='', flush=True)
    user_input = [None]

    def input_thread():
        user_input[0] = sys.stdin.readline().strip()

    thread = threading.Thread(target=input_thread)
    thread.daemon = True
    thread.start()
    thread.join(timeout)
    if thread.is_alive():
        print("\nNo input received. Proceeding with default option.")
        return ''
    return user_input[0]

def get_current_utc_time():
    return datetime.utcnow().replace(tzinfo=timezone.utc)


File: src/spotify_operations.py
===============================

# spotify_operations.py

import os
import sys
import logging
import time
from datetime import datetime, timezone
import sqlite3
from dotenv import load_dotenv
import spotipy
from spotipy.oauth2 import SpotifyOAuth
from rapidfuzz import fuzz
from src.utils import normalize_string
from src.database import Database
from typing import List, Dict, Tuple, Optional, Set
from concurrent.futures import ThreadPoolExecutor, TimeoutError

# Load environment variables
load_dotenv()

# Use environment variable for database file path
SPOTIFY_DB_FILE = os.getenv('SPOTIFY_DB_FILE', 'db/spotify_liked_songs.db')
LASTFM_DB_FILE = os.getenv('LASTFM_DB_FILE', 'db/lastfm_history.db')

class SpotifyOperations:
    """Handles operations related to Spotify, including searching and liking tracks and albums."""

    def __init__(self, db_file=SPOTIFY_DB_FILE):
        """Initialize the Spotify operations and create necessary database tables."""
        self.sp = spotipy.Spotify(
            auth_manager=SpotifyOAuth(scope="user-library-read user-library-modify"),
            requests_timeout=10  # Set a timeout of 10 seconds
        )
        self.db_file = db_file
        self.create_tables()

    def create_tables(self):
        """Create necessary tables in the database if they don't exist."""
        conn = sqlite3.connect(self.db_file)
        c = conn.cursor()
        
        # Create the liked_songs table if it doesn't exist
        c.execute('''CREATE TABLE IF NOT EXISTS liked_songs
                     (id TEXT PRIMARY KEY, name TEXT, artist TEXT, album TEXT, album_id TEXT, added_at TEXT)''')
        
        # Create metadata table if it doesn't exist
        c.execute('''CREATE TABLE IF NOT EXISTS metadata
                     (key TEXT PRIMARY KEY, value TEXT)''')
        
        # Create search_cache table if it doesn't exist
        c.execute('''CREATE TABLE IF NOT EXISTS search_cache
                     (name TEXT, artist TEXT, track_id TEXT, PRIMARY KEY (name, artist))''')
        
        # Create unfound_tracks table if it doesn't exist
        c.execute('''CREATE TABLE IF NOT EXISTS unfound_tracks
                     (artist TEXT, name TEXT, timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                      PRIMARY KEY (artist, name))''')
        
        # Create saved_albums table if it doesn't exist
        c.execute('''CREATE TABLE IF NOT EXISTS saved_albums
                     (id TEXT PRIMARY KEY, name TEXT, artist TEXT, added_at TEXT)''')
        
        conn.commit()
        conn.close()

    def fetch_all_liked_songs(self):
        offset = 0
        limit = 50
        all_tracks = []

        while True:
            results = self.sp.current_user_saved_tracks(limit=limit, offset=offset)
            tracks = results['items']
            if len(tracks) == 0:
                break
            all_tracks.extend(tracks)
            offset += limit

        conn = sqlite3.connect(self.db_file)
        c = conn.cursor()

        for item in all_tracks:
            track = item['track']
            name = normalize_string(track['name'])
            artist = normalize_string(track['artists'][0]['name'])
            album = normalize_string(track['album']['name'])
            album_id = track['album']['id']
            c.execute("INSERT OR REPLACE INTO liked_songs VALUES (?, ?, ?, ?, ?, ?)",
                      (track['id'], name, artist, album, album_id, item['added_at']))

        conn.commit()
        conn.close()

        return len(all_tracks)

    def get_liked_songs_set(self):
        conn = sqlite3.connect(self.db_file)
        c = conn.cursor()
        c.execute("SELECT name, artist FROM liked_songs")
        liked_songs = c.fetchall()
        conn.close()
        
        # Check for duplicates
        liked_set = set()
        duplicates = set()
        for name, artist in liked_songs:
            if (name, artist) in liked_set:
                duplicates.add((name, artist))
            else:
                liked_set.add((name, artist))
        
        logging.info(f"Retrieved {len(liked_set)} unique liked songs from local database")
        if duplicates:
            logging.warning(f"Found {len(duplicates)} duplicate entries in liked_songs table")
            for name, artist in list(duplicates)[:5]:  # Log first 5 duplicates
                logging.warning(f"Duplicate: {artist} - {name}")
        
        return liked_set

    def remove_duplicates(self):
        conn = sqlite3.connect(self.db_file)
        c = conn.cursor()
        c.execute("""
            DELETE FROM liked_songs
            WHERE rowid NOT IN (
                SELECT MIN(rowid)
                FROM liked_songs
                GROUP BY name, artist
            )
        """)
        removed = c.rowcount
        conn.commit()
        conn.close()
        logging.info(f"Removed {removed} duplicate entries from liked_songs table")

    def like_tracks(self, track_ids):
        batch_size = 50  # Spotify allows up to 50 tracks to be liked at once
        for i in range(0, len(track_ids), batch_size):
            batch = track_ids[i:i+batch_size]
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    self.sp.current_user_saved_tracks_add(tracks=batch)
                    logging.info(f"Liked {len(batch)} tracks")
                    # After liking tracks, add them to the local database
                    self._save_newly_liked_tracks(batch)
                    logging.info(f"Saved {len(batch)} newly liked tracks to local database")
                    break  # Success, exit retry loop
                except spotipy.exceptions.SpotifyException as e:
                    logging.error(f"Error liking tracks (attempt {attempt + 1}/{max_retries}): {e}")
                    if attempt < max_retries - 1:
                        time.sleep(2 ** attempt)  # Exponential backoff
                    else:
                        logging.error(f"Failed to like tracks after {max_retries} attempts")
                except Exception as e:
                    logging.error(f"Unexpected error liking tracks: {e}", exc_info=True)
                    break  # Exit retry loop for unexpected errors
            time.sleep(0.1)  # Add a small delay to avoid rate limiting

    def _save_newly_liked_tracks(self, track_ids):
        # Fetch details of the newly liked tracks in batches
        batch_size = 50
        tracks = []
        for i in range(0, len(track_ids), batch_size):
            batch = track_ids[i:i+batch_size]
            response = self.sp.tracks(batch)
            for track in response['tracks']:
                tracks.append({
                    'added_at': datetime.utcnow().replace(tzinfo=timezone.utc).isoformat(),
                    'track': track
                })
            time.sleep(0.1)  # To respect rate limits

        conn = sqlite3.connect(self.db_file)
        c = conn.cursor()
        for item in tracks:
            track = item['track']
            name = normalize_string(track['name'])
            artist = normalize_string(track['artists'][0]['name'])
            album = normalize_string(track['album']['name'])
            album_id = track['album']['id']
            
            # Check if the track already exists
            c.execute("SELECT id FROM liked_songs WHERE name = ? AND artist = ?", (name, artist))
            existing = c.fetchone()
            if existing:
                logging.info(f"Track already in database: {artist} - {name}")
            else:
                c.execute("INSERT INTO liked_songs VALUES (?, ?, ?, ?, ?, ?)",
                          (track['id'], name, artist, album, album_id, item['added_at']))
                logging.info(f"Saving newly liked track: {artist} - {name}")
        
        conn.commit()
        conn.close()

    def search_track(self, name, artist):
        """Search for a track on Spotify and return its ID if found."""
        # Check cache first
        cached_id = self.get_cached_track_id(name, artist)
        if cached_id is not None:
            return cached_id

        # Define query variations
        queries = [
            f"track:{name} artist:{artist}",
            f"track:{name}",
            f"{name} {artist}"
        ]

        for query in queries:
            try:
                track_id = self._search_and_match(query, name, artist)
                if track_id:
                    self.cache_track_id(name, artist, track_id)
                    return track_id
            except Exception as e:
                logging.error(f"Error searching for track '{name}' by '{artist}': {e}", exc_info=True)
                time.sleep(1)  # Add a small delay before trying the next query
                continue

        # Cache negative result
        self.cache_track_id(name, artist, None)
        return None

    def _search_and_match(self, query, name, artist):
        """Perform a search query and match results against the given name and artist."""
        max_retries = 3
        for attempt in range(max_retries):
            try:
                results = self.sp.search(q=query, type='track', limit=10)
                if results['tracks']['items']:
                    best_match = None
                    highest_score = 0
                    for item in results['tracks']['items']:
                        spotify_name = normalize_string(item['name'])
                        spotify_artist = normalize_string(item['artists'][0]['name'])
                        name_score = fuzz.token_sort_ratio(name, spotify_name)
                        artist_score = fuzz.token_sort_ratio(artist, spotify_artist)
                        total_score = (name_score + artist_score) / 2
                        if total_score > highest_score:
                            highest_score = total_score
                            best_match = item['id']
                    if highest_score > 80:  # Threshold can be adjusted
                        return best_match
                return None
            except spotipy.exceptions.SpotifyException as e:
                logging.error(f"Spotify API error during search (attempt {attempt + 1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    time.sleep(2 ** attempt)  # Exponential backoff
                else:
                    logging.error(f"Failed to search after {max_retries} attempts")
            except Exception as e:
                logging.error(f"Unexpected error during search: {e}", exc_info=True)
                break  # Exit retry loop for unexpected errors
            finally:
                time.sleep(0.1)  # Small delay to respect rate limits
        return None

    def get_cached_track_id(self, name, artist):
        conn = sqlite3.connect(self.db_file)
        c = conn.cursor()
        c.execute("SELECT track_id FROM search_cache WHERE name = ? AND artist = ?", (name, artist))
        result = c.fetchone()
        conn.close()
        if result:
            return result[0] if result[0] != 'NOT_FOUND' else None
        return None

    def cache_track_id(self, name, artist, track_id):
        if track_id is None:
            track_id = 'NOT_FOUND'
        conn = sqlite3.connect(self.db_file)
        c = conn.cursor()
        c.execute("INSERT OR REPLACE INTO search_cache (name, artist, track_id) VALUES (?, ?, ?)",
                  (name, artist, track_id))
        conn.commit()
        conn.close()

    def find_tracks_to_like(self, lastfm_tracks, min_play_count=5):
        spotify_liked = self.get_liked_songs_set()
        tracks_to_like = []
        processed_tracks = []

        for track in lastfm_tracks:
            if track[2] >= min_play_count:
                name, artist, play_count = track[1], track[0], track[2]
                processed_tracks.append((artist, name, play_count))

                logging.info(f"Checking track: {artist} - {name} (Play count: {play_count})")

                if not self.is_track_liked(name, artist, spotify_liked):
                    logging.info(f"Track not liked on Spotify: {artist} - {name}")
                    track_id = self.search_track(name, artist)
                    if track_id:
                        if not self.is_track_in_database(track_id):
                            tracks_to_like.append(track_id)
                            logging.info(f"Will like: {artist} - {name}")
                        else:
                            logging.info(f"Track already in database, skipping: {artist} - {name}")
                    else:
                        logging.info(f"Couldn't find track on Spotify: {artist} - {name}")
                        self.add_unfound_track(artist, name)
                else:
                    logging.info(f"Track already liked, skipping: {artist} - {name}")
            else:
                logging.info(f"Skipping track with low play count: {track[0]} - {track[1]} (Play count: {track[2]})")
                break

        # Mark processed tracks in the Last.fm database
        lastfm_db = Database(db_file=LASTFM_DB_FILE)
        lastfm_db.mark_tracks_as_processed(processed_tracks)

        logging.info(f"Found {len(processed_tracks)} tracks with {min_play_count}+ plays on Last.fm")
        logging.info(f"Of these, {len(tracks_to_like)} are new tracks to like on Spotify")
        return tracks_to_like

    def is_track_liked(self, name, artist, spotify_liked):
        normalized_name = normalize_string(name)
        normalized_artist = normalize_string(artist)
        return any(
            fuzz.ratio(normalized_name, liked_name) > 90 and
            fuzz.ratio(normalized_artist, liked_artist) > 90
            for liked_name, liked_artist in spotify_liked
        )

    def is_track_in_database(self, track_id):
        conn = sqlite3.connect(self.db_file)
        c = conn.cursor()
        c.execute("SELECT id FROM liked_songs WHERE id = ?", (track_id,))
        result = c.fetchone()
        conn.close()
        return result is not None

    def add_unfound_track(self, artist, name):
        """Add a track that couldn't be found on Spotify to the unfound_tracks table."""
        conn = sqlite3.connect(self.db_file)
        c = conn.cursor()
        c.execute("INSERT OR IGNORE INTO unfound_tracks (artist, name) VALUES (?, ?)", (artist, name))
        conn.commit()
        conn.close()

    def get_last_update_time(self):
        conn = sqlite3.connect(self.db_file)
        c = conn.cursor()
        c.execute("SELECT value FROM metadata WHERE key = 'last_update'")
        result = c.fetchone()
        conn.close()
        if result and result[0]:
            # Ensure the datetime is timezone-aware and in UTC
            return datetime.fromisoformat(result[0]).astimezone(timezone.utc)
        return None

    def set_last_update_time(self, update_time):
        conn = sqlite3.connect(self.db_file)
        c = conn.cursor()
        # Ensure update_time is in ISO format with timezone info
        c.execute("INSERT OR REPLACE INTO metadata (key, value) VALUES (?, ?)",
                  ('last_update', update_time.astimezone(timezone.utc).isoformat()))
        conn.commit()
        conn.close()

    def fetch_new_liked_songs(self):
        last_update = self.get_last_update_time()
        offset = 0
        limit = 50
        new_tracks = []
        max_iterations = 20  # Limit the number of iterations to prevent infinite loops

        logging.info("Fetching new liked songs from Spotify...")
        iterations = 0

        while iterations < max_iterations:
            try:
                results = self.sp.current_user_saved_tracks(limit=limit, offset=offset)
                if not results['items']:
                    break
                for item in results['items']:
                    added_at = datetime.strptime(item['added_at'], "%Y-%m-%dT%H:%M:%SZ").replace(tzinfo=timezone.utc)
                    if last_update and added_at <= last_update:
                        logging.info("Reached tracks already in local database.")
                        return new_tracks
                    new_tracks.append(item)
                offset += limit
                iterations += 1
                time.sleep(0.1)  # Small delay to respect rate limits
            except Exception as e:
                logging.error(f"Error fetching liked songs: {e}", exc_info=True)
                break

        logging.info(f"Fetched {len(new_tracks)} new liked songs from Spotify.")
        return new_tracks

    def update_liked_songs(self, force_full_fetch=False):
        last_update = self.get_last_update_time()
        if last_update is None or force_full_fetch:
            logging.info("Fetching all liked songs from Spotify.")
            total_tracks = self.fetch_all_liked_songs()
            logging.info(f"Fetched {total_tracks} liked songs from Spotify.")
            self.set_last_update_time(datetime.utcnow().replace(tzinfo=timezone.utc))
            
            # Add logging to verify database update
            conn = sqlite3.connect(self.db_file)
            c = conn.cursor()
            c.execute("SELECT COUNT(*) FROM liked_songs")
            total_liked_songs = c.fetchone()[0]
            conn.close()
            logging.info(f"Total liked songs in local database: {total_liked_songs}")
            
            return total_tracks
        else:
            new_tracks = self.fetch_new_liked_songs()
            if not new_tracks:
                logging.info("No new liked songs to update.")
                return 0
            self._save_tracks_to_db(new_tracks)
            if new_tracks:
                latest_added_at = max(
                    datetime.strptime(item['added_at'], "%Y-%m-%dT%H:%M:%SZ").replace(tzinfo=timezone.utc)
                    for item in new_tracks
                )
                self.set_last_update_time(latest_added_at)
                logging.info(f"Updated last update time to: {latest_added_at.isoformat()}")
            
            # Add logging to verify database update
            conn = sqlite3.connect(self.db_file)
            c = conn.cursor()
            c.execute("SELECT COUNT(*) FROM liked_songs")
            total_liked_songs = c.fetchone()[0]
            conn.close()
            logging.info(f"Total liked songs in local database after update: {total_liked_songs}")
            
            return len(new_tracks)

    def _save_tracks_to_db(self, tracks):
        conn = sqlite3.connect(self.db_file)
        c = conn.cursor()
        for item in tracks:
            track = item['track']
            name = normalize_string(track['name'])
            artist = normalize_string(track['artists'][0]['name'])
            album = normalize_string(track['album']['name'])
            album_id = track['album']['id']
            c.execute("INSERT OR REPLACE INTO liked_songs VALUES (?, ?, ?, ?, ?, ?)",
                      (track['id'], name, artist, album, album_id, item['added_at']))
        conn.commit()
        conn.close()

    def verify_local_database(self):
        conn = sqlite3.connect(self.db_file)
        c = conn.cursor()
        c.execute("SELECT COUNT(*) FROM liked_songs")
        count = c.fetchone()[0]
        logging.info(f"Local database contains {count} liked songs")
        c.execute("SELECT name, artist FROM liked_songs LIMIT 5")
        sample = c.fetchall()
        logging.info(f"Sample of liked songs in database: {sample}")
        conn.close()

    def log_unfound_tracks(self):
        conn = sqlite3.connect(self.db_file)
        c = conn.cursor()
        c.execute("SELECT artist, name FROM unfound_tracks")
        unfound = c.fetchall()
        conn.close()
        logging.info(f"Unfound tracks in database: {len(unfound)}")
        for artist, name in unfound[:5]:  # Log first 5 for brevity
            logging.info(f"Unfound: {artist} - {name}")

    def get_all_album_ids(self):
        conn = sqlite3.connect(self.db_file)
        c = conn.cursor()
        c.execute("SELECT DISTINCT album_id FROM liked_songs")
        album_ids = [row[0] for row in c.fetchall()]
        conn.close()
        return album_ids

    def get_album_ids_since(self, since_datetime):
        conn = sqlite3.connect(self.db_file)
        c = conn.cursor()
        c.execute("SELECT DISTINCT album_id FROM liked_songs WHERE added_at > ?",
                  (since_datetime.isoformat(),))
        album_ids = [row[0] for row in c.fetchall()]
        conn.close()
        return album_ids

    def search_album(self, album_name: str, artist_name: str) -> Optional[str]:
        """
        Search for an album on Spotify and return its ID if found.
        """
        normalized_album = normalize_string(album_name)
        normalized_artist = normalize_string(artist_name)
        query = f"album:{normalized_album} artist:{normalized_artist}"
        logging.info(f"Searching for album on Spotify: {artist_name} - {album_name}")
        try:
            results = self.sp.search(q=query, type='album', limit=5)
            if results['albums']['items']:
                # Use fuzzy matching to find the best match
                best_match_id = None
                highest_score = 0
                for item in results['albums']['items']:
                    spotify_album = normalize_string(item['name'])
                    spotify_artist = normalize_string(item['artists'][0]['name'])
                    album_score = fuzz.token_sort_ratio(normalized_album, spotify_album)
                    artist_score = fuzz.token_sort_ratio(normalized_artist, spotify_artist)
                    total_score = (album_score + artist_score) / 2
                    if total_score > highest_score:
                        highest_score = total_score
                        best_match_id = item['id']
                if highest_score > 80:
                    logging.info(f"Found album on Spotify with score {highest_score}: ID {best_match_id}")
                    return best_match_id
                else:
                    logging.info("No matching album found with sufficient confidence.")
            else:
                logging.info("No albums found in search results.")
        except Exception as e:
            logging.error(f"Error searching for album: {e}", exc_info=True)
        return None

    def fetch_all_saved_albums(self):
        """Fetch all saved albums from Spotify and store them in the local database."""
        offset = 0
        limit = 50
        all_albums = []

        logging.info("Fetching saved albums from Spotify...")
        while True:
            results = self.sp.current_user_saved_albums(limit=limit, offset=offset)
            albums = results['items']
            if not albums:
                break
            all_albums.extend(albums)
            offset += limit
            time.sleep(0.1)  # Respect rate limits

        conn = sqlite3.connect(self.db_file)
        c = conn.cursor()

        for item in all_albums:
            album = item['album']
            name = normalize_string(album['name'])
            artist = normalize_string(album['artists'][0]['name'])
            album_id = album['id']
            added_at = item['added_at']
            c.execute("INSERT OR REPLACE INTO saved_albums VALUES (?, ?, ?, ?)",
                      (album_id, name, artist, added_at))

        conn.commit()
        conn.close()

        logging.info(f"Fetched and stored {len(all_albums)} saved albums.")
        return len(all_albums)

    def get_saved_albums_set(self) -> Set[str]:
        """Retrieve set of album IDs that are saved in the local database."""
        conn = sqlite3.connect(self.db_file)
        c = conn.cursor()
        c.execute("SELECT id FROM saved_albums")
        saved_albums = set(row[0] for row in c.fetchall())
        conn.close()
        logging.info(f"Retrieved {len(saved_albums)} saved albums from local database.")
        return saved_albums

    def save_album(self, album_id: str) -> None:
        """Save an album to the user's Spotify library and update the local database."""
        try:
            self.sp.current_user_saved_albums_add([album_id])
            logging.info(f"Saved album to Spotify library: {album_id}")

            # Fetch album details to store in the database
            album = self.sp.album(album_id)
            name = normalize_string(album['name'])
            artist = normalize_string(album['artists'][0]['name'])
            added_at = datetime.utcnow().replace(tzinfo=timezone.utc).isoformat()

            # Update local database
            conn = sqlite3.connect(self.db_file)
            c = conn.cursor()
            c.execute("INSERT OR REPLACE INTO saved_albums VALUES (?, ?, ?, ?)",
                      (album_id, name, artist, added_at))
            conn.commit()
            conn.close()
            logging.info(f"Updated local database with album: {artist} - {name}")

        except Exception as e:
            logging.error(f"Error saving album {album_id}: {e}", exc_info=True)

    def get_album_tracks(self, album_id: str) -> List[dict]:
        """Retrieve all tracks from an album."""
        tracks = []
        try:
            with ThreadPoolExecutor(max_workers=1) as executor:
                future = executor.submit(self.sp.album_tracks, album_id)
                try:
                    results = future.result(timeout=10)
                except TimeoutError:
                    logging.error(f"TimeoutError: Fetching album tracks for album_id {album_id} took too long.")
                    return []
                except Exception as e:
                    logging.error(f"Error fetching album tracks for album_id {album_id}: {e}", exc_info=True)
                    return []

            tracks.extend(results['items'])
            max_iterations = 10  # Limit to prevent infinite loops
            iteration = 0
            while results['next'] and iteration < max_iterations:
                logging.info(f"Fetching next page of tracks (iteration {iteration + 1})")
                with ThreadPoolExecutor(max_workers=1) as executor:
                    future = executor.submit(self.sp.next, results)
                    try:
                        results = future.result(timeout=10)
                    except TimeoutError:
                        logging.error(f"TimeoutError: Fetching next page of tracks for album_id {album_id} took too long.")
                        break
                    except Exception as e:
                        logging.error(f"Error fetching next page of tracks for album_id {album_id}: {e}", exc_info=True)
                        break
                tracks.extend(results['items'])
                iteration += 1

            logging.info(f"Retrieved {len(tracks)} tracks from album {album_id}")
        except Exception as e:
            logging.error(f"Error fetching tracks for album {album_id}: {e}", exc_info=True)
        return tracks

File: src/scripts/album_saver.py
================================

#!/usr/bin/env python3
# album_saver.py

import os
import sys
import logging
import sqlite3
from datetime import datetime, timezone
from dotenv import load_dotenv
from typing import List, Set, Optional
import time
import spotipy

# Modify the sys.path to include the project root
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
sys.path.insert(0, project_root)

from src.database import Database
from src.spotify_operations import SpotifyOperations
from src.utils import normalize_string, get_user_input_with_timeout

# Load environment variables
load_dotenv()

LASTFM_DB_FILE = os.getenv('LASTFM_DB_FILE', 'db/lastfm_history.db')
SPOTIFY_DB_FILE = os.getenv('SPOTIFY_DB_FILE', 'db/spotify_liked_songs.db')
ALBUM_SAVER_DB_FILE = os.path.join(project_root, 'db', 'album_saver.db')

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    filename='logs/album_saver.log',
    filemode='a'
)
console = logging.StreamHandler()
console.setLevel(logging.INFO)
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
console.setFormatter(formatter)
logging.getLogger('').addHandler(console)

class AlbumSaver:
    def __init__(self, db_file: str = SPOTIFY_DB_FILE):
        """Initialize the AlbumSaver class."""
        self.lastfm_db = Database(db_file=LASTFM_DB_FILE)
        self.spotify_ops = SpotifyOperations(db_file=SPOTIFY_DB_FILE)
        self.sp = self.spotify_ops.sp  # Use the Spotify client from SpotifyOperations
        # Ensure the Spotify client is initialized with a timeout
        if not hasattr(self.sp, 'requests_timeout'):
            self.sp = spotipy.Spotify(auth_manager=self.sp.auth_manager, requests_timeout=10)
        self.create_album_saver_table()
        self.saved_albums = self.get_all_saved_albums()  # Load saved albums from local database

    def create_album_saver_table(self) -> None:
        """Create the necessary tables in the album_saver database."""
        conn = sqlite3.connect(ALBUM_SAVER_DB_FILE)
        c = conn.cursor()
        c.execute('''
            CREATE TABLE IF NOT EXISTS saved_albums (
                id TEXT PRIMARY KEY,
                name TEXT,
                artist TEXT,
                last_checked DATETIME
            )
        ''')
        c.execute('''
            CREATE TABLE IF NOT EXISTS metadata (
                key TEXT PRIMARY KEY,
                value TEXT
            )
        ''')
        conn.commit()
        conn.close()
        logging.info("Initialized album_saver database tables.")

    def fetch_saved_albums(self) -> None:
        """Fetch saved albums from Spotify and store them in the album_saver database."""
        offset = 0
        limit = 50
        all_albums = []

        logging.info("Fetching saved albums from Spotify...")
        while True:
            results = self.sp.current_user_saved_albums(limit=limit, offset=offset)
            albums = results['items']
            if not albums:
                break
            all_albums.extend(albums)
            offset += limit
            time.sleep(0.1)  # Respect rate limits

        conn = sqlite3.connect(ALBUM_SAVER_DB_FILE)
        c = conn.cursor()

        for item in all_albums:
            album = item['album']
            name = normalize_string(album['name'])
            artist = normalize_string(album['artists'][0]['name'])
            album_id = album['id']
            added_at = item['added_at']
            c.execute("INSERT OR REPLACE INTO saved_albums VALUES (?, ?, ?, ?)",
                      (album_id, name, artist, added_at))

        conn.commit()
        conn.close()

        logging.info(f"Fetched and stored {len(all_albums)} saved albums.")

    def get_all_saved_albums(self) -> Set[str]:
        """Retrieve all saved album IDs from the album_saver database."""
        conn = sqlite3.connect(ALBUM_SAVER_DB_FILE)
        c = conn.cursor()
        c.execute("SELECT id FROM saved_albums")
        saved_albums = set(row[0] for row in c.fetchall())
        conn.close()
        logging.info(f"Retrieved {len(saved_albums)} saved albums from album_saver database.")
        return saved_albums

    def get_last_update_time(self) -> Optional[datetime]:
        """Retrieve the last update time from the metadata table."""
        conn = sqlite3.connect(ALBUM_SAVER_DB_FILE)
        c = conn.cursor()
        c.execute("SELECT value FROM metadata WHERE key = 'last_update'")
        result = c.fetchone()
        conn.close()
        if result and result[0]:
            return datetime.fromisoformat(result[0]).astimezone(timezone.utc)
        return None

    def set_last_update_time(self, update_time: datetime) -> None:
        """Set the last update time in the metadata table."""
        conn = sqlite3.connect(ALBUM_SAVER_DB_FILE)
        c = conn.cursor()
        c.execute(
            "INSERT OR REPLACE INTO metadata (key, value) VALUES (?, ?)",
            ('last_update', update_time.astimezone(timezone.utc).isoformat())
        )
        conn.commit()
        conn.close()
        logging.info(f"Set last update time to: {update_time.isoformat()}")

    def process_albums(self, force_full_check: bool = False) -> None:
        """Main method to process albums and save them to Spotify if they meet criteria."""
        last_update = self.get_last_update_time()
        if force_full_check or last_update is None:
            logging.info("Performing full album check.")
            albums_to_check = self.lastfm_db.get_all_albums()
        else:
            logging.info(f"Checking albums updated since {last_update.isoformat()}")
            albums_to_check = self.lastfm_db.get_albums_since(last_update)

        logging.info(f"Found {len(albums_to_check)} albums to check.")

        new_albums_added = 0
        for index, album in enumerate(albums_to_check, 1):
            try:
                album_name = album['name']
                artist_name = album['artist']
                logging.info(f"Processing album {index}/{len(albums_to_check)}: {artist_name} - {album_name}")

                # Search for album on Spotify
                album_id = self.spotify_ops.search_album(album_name, artist_name)
                if album_id:
                    if album_id in self.saved_albums:
                        logging.info(f"Album already saved: {artist_name} - {album_name}")
                        continue  # Skip already saved albums

                    # Check if album meets criteria
                    if self.check_album_conditions(album_id):
                        self.save_album_to_library(album_id)
                        new_albums_added += 1
                        self.saved_albums.add(album_id)  # Update the saved albums set
                    else:
                        logging.info(f"Album does not meet criteria: {artist_name} - {album_name}")
                else:
                    logging.info(f"Album not found on Spotify: {artist_name} - {album_name}")
            except Exception as e:
                logging.error(f"Error processing album {artist_name} - {album_name}: {e}", exc_info=True)
                continue  # Continue processing next album

        logging.info(f"Processed {len(albums_to_check)} albums. Added {new_albums_added} new albums.")
        self.set_last_update_time(datetime.now(timezone.utc))

    def check_album_conditions(self, album_id: str) -> bool:
        """Check if an album meets the criteria to be saved."""
        logging.info(f"Starting to check album conditions for album_id: {album_id}")
        try:
            album = self.sp.album(album_id)  # Removed timeout parameter
            album_name = album['name']
            artist_name = album['artists'][0]['name']
            logging.info(f"Retrieved album details: {artist_name} - {album_name}")

            if 'various artists' in artist_name.lower():
                logging.info("Skipping 'Various Artists' album.")
                return False

            logging.info("Fetching album tracks...")
            album_tracks = self.get_album_tracks(album_id)
            total_tracks = len(album_tracks)
            logging.info(f"Total tracks in album: {total_tracks}")

            if total_tracks <= 6:
                logging.info("Album has 6 or fewer tracks; skipping.")
                return False

            listened_tracks = 0
            tracks_listened_3_times = 0

            logging.info("Processing individual tracks...")
            conn = sqlite3.connect(LASTFM_DB_FILE)
            c = conn.cursor()
            try:
                for idx, track in enumerate(album_tracks, 1):
                    normalized_track = normalize_string(track['name'])
                    normalized_artist = normalize_string(artist_name)
                    logging.info(f"Processing track {idx}/{total_tracks}: {normalized_track}")
                    c.execute(
                        "SELECT listen_count FROM tracks WHERE name = ? AND artist = ?",
                        (normalized_track, normalized_artist)
                    )
                    result = c.fetchone()
                    listen_count = result[0] if result else 0
                    logging.info(f"Track {idx}/{total_tracks}: {track['name']} - Listen count: {listen_count}")
                    if listen_count > 0:
                        listened_tracks += 1
                    if listen_count >= 3:
                        tracks_listened_3_times += 1
            except Exception as e:
                logging.error(f"Error processing tracks: {e}", exc_info=True)
                return False
            finally:
                conn.close()

            condition1 = listened_tracks >= 0.75 * total_tracks
            condition2 = tracks_listened_3_times >= 3

            logging.info(f"Listened tracks: {listened_tracks}/{total_tracks}, "
                         f"Tracks listened 3+ times: {tracks_listened_3_times}")
            logging.info(f"Condition 1 met: {condition1}, Condition 2 met: {condition2}")

            return condition1 or condition2
        except Exception as e:
            logging.error(f"Error in check_album_conditions for album_id {album_id}: {e}", exc_info=True)
            return False

    def get_album_tracks(self, album_id: str) -> List[dict]:
        """Retrieve all tracks from an album."""
        tracks = []
        try:
            results = self.sp.album_tracks(album_id)  # Removed timeout parameter
            tracks.extend(results['items'])
            max_iterations = 10  # Limit to prevent infinite loops
            iteration = 0
            while results['next'] and iteration < max_iterations:
                logging.info(f"Fetching next page of tracks (iteration {iteration + 1})")
                results = self.sp.next(results)  # Removed timeout parameter
                tracks.extend(results['items'])
                iteration += 1
            logging.info(f"Retrieved {len(tracks)} tracks from album {album_id}")
        except Exception as e:
            logging.error(f"Error fetching tracks for album {album_id}: {e}", exc_info=True)
        return tracks

    def save_album_to_library(self, album_id: str) -> None:
        """Save an album to the Spotify library."""
        try:
            album = self.sp.album(album_id)
            album_name = album['name']
            artist_name = album['artists'][0]['name']
            logging.info(f"Saving album: {artist_name} - {album_name}")

            # Save the album to the library
            self.sp.current_user_saved_albums_add([album_id])
            logging.info(f"Album saved: {artist_name} - {album_name}")
            self.update_saved_album(album_id, album_name, artist_name)
        except Exception as e:
            logging.error(f"Error saving album {album_id}: {e}", exc_info=True)

    def update_saved_album(self, album_id: str, album_name: str, artist_name: str) -> None:
        """Update the saved_albums table with the new album."""
        conn = sqlite3.connect(ALBUM_SAVER_DB_FILE)
        c = conn.cursor()
        now = datetime.utcnow().replace(tzinfo=timezone.utc).isoformat()
        c.execute(
            "INSERT OR REPLACE INTO saved_albums (id, name, artist, last_checked) VALUES (?, ?, ?, ?)",
            (album_id, album_name, artist_name, now)
        )
        conn.commit()
        conn.close()
        logging.info(f"Updated album_saver database for album: {artist_name} - {album_name}")

def main():
    try:
        album_saver = AlbumSaver()

        # Prompt the user for full or update check
        prompt = "Do you want to perform a full check or an update check? (Enter 'full' or 'update' within 10 seconds, default is 'update'): "
        user_choice = get_user_input_with_timeout(prompt, timeout=10)

        if user_choice.lower() == 'full':
            force_full_check = True
            logging.info("User selected full check.")
        else:
            force_full_check = False
            logging.info("Proceeding with update check.")

        # Fetch saved albums from Spotify and update local database
        album_saver.fetch_saved_albums()
        album_saver.saved_albums = album_saver.get_all_saved_albums()  # Refresh saved albums set

        album_saver.process_albums(force_full_check)

    except Exception as e:
        logging.error(f"An unexpected error occurred: {e}", exc_info=True)

if __name__ == "__main__":
    main()

File: src/scripts/spotify_deduplicator.py
=========================================

import os
import sys

# Modify the sys.path to include the project root
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
sys.path.insert(0, project_root)

from src.utils import normalize_string

import logging
import time
from datetime import datetime, timezone
import sqlite3
from dotenv import load_dotenv
import spotipy
from spotipy.oauth2 import SpotifyOAuth
from rapidfuzz import fuzz, process

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s',
                    filename='logs/spotify_deduplicator.log', filemode='a')

# Load environment variables
load_dotenv()

# Database file path
SPOTIFY_DB_FILE = os.getenv('SPOTIFY_DB_FILE', 'db/spotify_liked_songs.db')

class SpotifyDeduplicator:
    def __init__(self):
        self.sp = spotipy.Spotify(auth_manager=SpotifyOAuth(scope="user-library-read user-library-modify"))

    def fetch_all_liked_songs(self):
        offset = 0
        limit = 50
        all_tracks = []

        while True:
            results = self.sp.current_user_saved_tracks(limit=limit, offset=offset)
            tracks = results['items']
            if len(tracks) == 0:
                break
            all_tracks.extend(tracks)
            offset += limit

        logging.info(f"Fetched {len(all_tracks)} liked songs from Spotify.")
        return all_tracks

    def group_duplicates(self, tracks):
        track_map = {}
        for item in tracks:
            track = item['track']
            name = normalize_string(track['name'])
            artist = normalize_string(track['artists'][0]['name'])
            key = f"{artist} {name}"
            if key not in track_map:
                track_map[key] = []
            track_map[key].append(track)
        duplicates = {k: v for k, v in track_map.items() if len(v) > 1}
        logging.info(f"Found {len(duplicates)} groups of duplicate tracks.")
        return duplicates

    def select_preferred_track(self, tracks):
        # Apply your rules to select the preferred track
        # Rule 1: Prefer remastered versions
        remastered_tracks = [t for t in tracks if 'remaster' in t['name'].lower()]
        if remastered_tracks:
            tracks = remastered_tracks

        # Rule 2: Prefer tracks from deluxe/longer albums
        if len(tracks) > 1:
            album_lengths = {}
            for t in tracks:
                album_id = t['album']['id']
                if album_id not in album_lengths:
                    album = self.sp.album(album_id)
                    album_lengths[album_id] = len(album['tracks']['items'])
                t['album_length'] = album_lengths[album_id]
            max_length = max(t['album_length'] for t in tracks)
            tracks = [t for t in tracks if t['album_length'] == max_length]

        # Return the first track if multiple remain
        return tracks[0]

    def deduplicate(self):
        all_tracks = self.fetch_all_liked_songs()
        duplicates = self.group_duplicates(all_tracks)
        tracks_to_remove = []
        for key, tracks in duplicates.items():
            preferred_track = self.select_preferred_track(tracks)
            for t in tracks:
                if t['id'] != preferred_track['id']:
                    tracks_to_remove.append(t['id'])
                    logging.info(f"Removing duplicate track: {t['name']} by {t['artists'][0]['name']}")
        if tracks_to_remove:
            batch_size = 50
            for i in range(0, len(tracks_to_remove), batch_size):
                batch = tracks_to_remove[i:i+batch_size]
                retry_count = 0
                while retry_count < 3:  # Maximum 3 retries
                    try:
                        self.sp.current_user_saved_tracks_delete(tracks=batch)
                        break  # Success, exit the retry loop
                    except spotipy.exceptions.SpotifyException as e:
                        if e.http_status == 429:
                            retry_after = int(e.headers.get('Retry-After', 5))
                            logging.warning(f"Rate limited by Spotify. Retrying after {retry_after} seconds.")
                            time.sleep(retry_after)
                            retry_count += 1
                        else:
                            logging.error(f"Error removing tracks: {e}")
                            break  # Exit the retry loop for non-rate-limiting errors
                    except Exception as e:
                        logging.error(f"Unexpected error removing tracks: {e}")
                        break
                time.sleep(0.1)
            logging.info(f"Removed {len(tracks_to_remove)} duplicate tracks.")
        else:
            logging.info("No duplicates found to remove.")

def main():
    try:
        deduplicator = SpotifyDeduplicator()
        deduplicator.deduplicate()
    except KeyboardInterrupt:
        logging.info("Program interrupted by user. Exiting gracefully.")
        sys.exit(0)
    except Exception as e:
        logging.error(f"An unexpected error occurred: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()


File: src/scripts/__init__.py
=============================



File: src/scripts/lastfm_spotify_liker.py
=========================================

#!/usr/bin/env python3
# last_fm_spotify_liker.py

import os
import sys
import logging
import time
import sqlite3
import threading
from datetime import datetime, timezone
import requests
from dotenv import load_dotenv
from typing import Optional, List, Dict, Any

# Modify the sys.path to include the project root
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
sys.path.insert(0, project_root)

from src.database import Database
from src.spotify_operations import SpotifyOperations
from src.utils import normalize_string, get_user_input_with_timeout

# Load environment variables
load_dotenv()

# Last.fm API credentials
LASTFM_API_KEY = os.getenv('LASTFM_API_KEY')
LASTFM_USER = os.getenv('LASTFM_USER')
MIN_PLAY_COUNT = int(os.getenv('MIN_PLAY_COUNT', 5))

# Database file paths
LASTFM_DB_FILE = os.getenv('LASTFM_DB_FILE', 'db/lastfm_history.db')
SPOTIFY_DB_FILE = os.getenv('SPOTIFY_DB_FILE', 'db/spotify_liked_songs.db')

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    filename='logs/lastfm_spotify_liker.log',
    filemode='a'
)
console = logging.StreamHandler()
console.setLevel(logging.INFO)
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
console.setFormatter(formatter)
logging.getLogger('').addHandler(console)

def get_new_lastfm_tracks(db: Database, from_timestamp: Optional[int] = None) -> int:
    """
    Fetch new tracks from Last.fm and update the local database.

    Args:
        db (Database): The database instance to update.
        from_timestamp (int, optional): Unix timestamp to fetch tracks from.

    Returns:
        int: Number of tracks fetched and processed.
    """
    url = 'http://ws.audioscrobbler.com/2.0/'
    params = {
        'method': 'user.getrecenttracks',
        'user': LASTFM_USER,
        'api_key': LASTFM_API_KEY,
        'format': 'json',
        'limit': 200,
    }
    if from_timestamp:
        params['from'] = from_timestamp
        logging.info(f"Fetching tracks from timestamp: {from_timestamp} ({datetime.fromtimestamp(from_timestamp, tz=timezone.utc).isoformat()})")
    else:
        logging.info("Fetching all tracks without a 'from' timestamp.")

    all_tracks = []
    page = 1

    logging.info("Starting to fetch tracks from Last.fm...")

    while True:
        params['page'] = page
        try:
            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()
            data = response.json()

            if 'error' in data:
                logging.error(f"Error fetching Last.fm tracks: {data['message']}")
                break

            tracks = data['recenttracks']['track']
            if not isinstance(tracks, list):
                tracks = [tracks]
            all_tracks.extend(tracks)

            total_pages = int(data['recenttracks']['@attr'].get('totalPages', 1))
            logging.info(f"Fetched page {page} of {total_pages} ({len(tracks)} tracks)")

            if page >= total_pages:
                break
            page += 1

        except requests.RequestException as e:
            logging.error(f"Network error when fetching Last.fm tracks: {e}")
            time.sleep(5)
            continue  # Retry on network errors
        except Exception as e:
            logging.error(f"Unexpected error in get_new_lastfm_tracks: {e}", exc_info=True)
            break

    processed_count = 0
    for track in all_tracks:
        try:
            if 'date' in track:
                track_date = datetime.fromtimestamp(int(track['date']['uts']), tz=timezone.utc)
            else:
                track_date = datetime.utcnow().replace(tzinfo=timezone.utc)  # Use accurate UTC time

            artist_name = track['artist']['#text'] if isinstance(track['artist'], dict) else track['artist']
            album_name = track['album']['#text'] if isinstance(track.get('album'), dict) else track.get('album', '')
            track_name = track['name']

            db.add_or_update_track({
                'artist': artist_name,
                'name': track_name,
                'album': album_name,
                'date': track_date,
                'mbid': track.get('mbid', '')
            })
            processed_count += 1
        except Exception as e:
            logging.error(f"Error processing track: {track}", exc_info=True)
            continue

    logging.info(f"Processed {processed_count} tracks from Last.fm")
    return processed_count

def main():
    try:
        lastfm_db = Database(db_file=LASTFM_DB_FILE)
        spotify_ops = SpotifyOperations(db_file=SPOTIFY_DB_FILE)

        # Ensure the processed column exists
        lastfm_db.add_processed_column()

        spotify_ops.verify_local_database()  # Verify database at the start

        # Check for and remove duplicates
        spotify_ops.remove_duplicates()

        # Check if databases exist
        if not os.path.exists(LASTFM_DB_FILE) or not os.path.exists(SPOTIFY_DB_FILE):
            logging.info("Database files not found. Performing full update without prompting.")
            force_full_fetch = True
            last_update = None
        else:
            # Prompt the user for full or incremental update
            prompt = "Do you want to perform a full update or an incremental update? (Enter 'full' or 'incremental' within 10 seconds, default is 'incremental'): "
            user_choice = get_user_input_with_timeout(prompt, timeout=10)

            if user_choice.lower() == 'full':
                force_full_fetch = True
                logging.info("User selected full update.")
                last_update = None
            else:
                force_full_fetch = False
                last_update = lastfm_db.get_last_update_time()
                if last_update:
                    # Ensure last_update is timezone-aware and in UTC
                    if last_update.tzinfo is None:
                        last_update = last_update.replace(tzinfo=timezone.utc)
                    logging.info(f"Proceeding with incremental update since {last_update.isoformat()}")
                else:
                    logging.info("No previous update time found. Performing full update.")
                    force_full_fetch = True

        # Update Last.fm tracks
        if force_full_fetch:
            logging.info("Fetching all Last.fm tracks (full update)")
            new_tracks_count = get_new_lastfm_tracks(lastfm_db)
        else:
            from_timestamp = int(last_update.timestamp())
            logging.info(f"Fetching Last.fm tracks since {last_update.isoformat()} (timestamp: {from_timestamp})")
            new_tracks_count = get_new_lastfm_tracks(lastfm_db, from_timestamp)
        logging.info(f"Added or updated {new_tracks_count} tracks from Last.fm")

        # Update Spotify liked songs
        logging.info("Updating Spotify liked songs...")
        spotify_ops.update_liked_songs()
        logging.info("Spotify liked songs updated.")

        # Get frequently played tracks from Last.fm
        frequently_played = lastfm_db.get_frequently_played_tracks(MIN_PLAY_COUNT)
        logging.info(f"Found {len(frequently_played)} tracks played more than {MIN_PLAY_COUNT} times on Last.fm")

        # Find tracks to be liked
        tracks_to_like = spotify_ops.find_tracks_to_like(frequently_played, min_play_count=MIN_PLAY_COUNT)

        if tracks_to_like:
            logging.info(f"Found {len(tracks_to_like)} new tracks to like on Spotify:")
            for track_id in tracks_to_like:
                try:
                    logging.info(f"Fetching track info for track ID: {track_id}")
                    # Set a timeout for the API call
                    track_info = spotify_ops.sp.track(track_id)
                    logging.info(f"  - {track_info['artists'][0]['name']} - {track_info['name']}")
                except Exception as e:
                    logging.error(f"Error fetching track info for track ID {track_id}: {e}", exc_info=True)
                    continue

            try:
                # Like the tracks on Spotify
                spotify_ops.like_tracks(tracks_to_like)
                logging.info(f"Finished liking {len(tracks_to_like)} tracks on Spotify")
            except Exception as e:
                logging.error(f"Error liking tracks on Spotify: {e}", exc_info=True)
        else:
            logging.info("No new tracks to like on Spotify")

        # Update Spotify liked songs again to ensure local database is current
        spotify_ops.update_liked_songs()

        # Check for and remove duplicates again
        spotify_ops.remove_duplicates()

        spotify_ops.verify_local_database()  # Verify database at the end

    except sqlite3.OperationalError as e:
        logging.error(f"Database error: {e}", exc_info=True)
        sys.exit(1)
    except Exception as e:
        logging.error(f"An unexpected error occurred: {e}", exc_info=True)
        sys.exit(1)

if __name__ == "__main__":
    main()

File: src/scripts/remove_duplicate_albums.py
============================================

# remove_duplicate_albums.py

import os
import sys

# Modify the sys.path to include the project root
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
sys.path.insert(0, project_root)

import spotipy
from spotipy.oauth2 import SpotifyOAuth
from dotenv import load_dotenv
import random
import logging

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s',
                    filename='logs/remove_duplicate_albums.log', filemode='a')

# Load environment variables from .env file
load_dotenv()

# Set up Spotify client
SPOTIPY_CLIENT_ID = os.getenv('SPOTIPY_CLIENT_ID')
SPOTIPY_CLIENT_SECRET = os.getenv('SPOTIPY_CLIENT_SECRET')
SPOTIPY_REDIRECT_URI = os.getenv('SPOTIPY_REDIRECT_URI')

print(f"SPOTIPY_CLIENT_ID: {SPOTIPY_CLIENT_ID}")
print(f"SPOTIPY_CLIENT_SECRET: {SPOTIPY_CLIENT_SECRET}")
print(f"SPOTIPY_REDIRECT_URI: {SPOTIPY_REDIRECT_URI}")

if not SPOTIPY_CLIENT_ID or not SPOTIPY_CLIENT_SECRET or not SPOTIPY_REDIRECT_URI:
    raise ValueError("Spotify credentials not found in .env file.")

def get_spotify_client():
    return spotipy.Spotify(auth_manager=SpotifyOAuth(scope="user-library-read user-library-modify"))

def get_albums_to_remove(sp):
    albums_to_remove = []
    offset = 0
    batch_size = 50
    album_dict = {}

    while True:
        results = sp.current_user_saved_albums(limit=batch_size, offset=offset)
        if not results['items']:
            break
        
        for item in results['items']:
            album = item['album']
            artist = album['artists'][0]['name']
            album_name = album['name']
            album_id = album['id']

            if 'various artists' in artist.lower():
                albums_to_remove.append((album_id, album_name, artist))
            else:
                key = f"{artist.lower()}:{album_name.lower()}"
                if key in album_dict:
                    album_dict[key].append((album_id, album_name, artist))
                else:
                    album_dict[key] = [(album_id, album_name, artist)]
        
        offset += batch_size

    # Check for duplicates
    for albums in album_dict.values():
        if len(albums) > 1:
            albums_to_keep = choose_albums_to_keep(sp, albums)
            albums_to_remove.extend([album for album in albums if album not in albums_to_keep])

    return albums_to_remove

def choose_albums_to_keep(sp, albums):
    deluxe = None
    remastered = None
    normal = None
    max_liked_songs = -1
    albums_with_max = []

    for album in albums:
        album_id, album_name, _ = album
        if 'deluxe' in album_name.lower():
            deluxe = album
        elif 'remaster' in album_name.lower():
            remastered = album
        else:
            normal = album

        liked_songs = count_liked_songs(sp, album_id)
        if liked_songs > max_liked_songs:
            max_liked_songs = liked_songs
            albums_with_max = [album]
        elif liked_songs == max_liked_songs:
            albums_with_max.append(album)

    to_keep = []
    if deluxe:
        to_keep.append(deluxe)
    if remastered and remastered not in to_keep:
        to_keep.append(remastered)
    if normal and normal not in to_keep:
        to_keep.append(normal)

    if not to_keep:
        to_keep = [random.choice(albums_with_max)]

    return to_keep

def count_liked_songs(sp, album_id):
    tracks = sp.album_tracks(album_id)['items']
    liked_count = 0
    for track in tracks:
        if sp.current_user_saved_tracks_contains([track['id']])[0]:
            liked_count += 1
    return liked_count

def remove_albums(sp, albums_to_remove):
    for i in range(0, len(albums_to_remove), 50):
        batch = albums_to_remove[i:i+50]
        sp.current_user_saved_albums_delete([album[0] for album in batch])
        for album in batch:
            print(f"Removed: {album[2]} - {album[1]}")

def main():
    sp = get_spotify_client()
    
    print("Searching for albums to remove...")
    albums_to_remove = get_albums_to_remove(sp)
    
    if albums_to_remove:
        print(f"Found {len(albums_to_remove)} albums to remove:")
        for album in albums_to_remove:
            print(f"  {album[2]} - {album[1]}")
        confirm = input("Do you want to remove these albums? (y/n): ")
        if confirm.lower() == 'y':
            remove_albums(sp, albums_to_remove)
            print(f"Total albums removed: {len(albums_to_remove)}")
        else:
            print("Operation cancelled.")
    else:
        print("No albums to remove found in your library.")

if __name__ == "__main__":
    main()

File: src/scripts/hot_100_playlist.py
=====================================

#!/usr/bin/env python3
# hot_100_playlist.py

import os
import sys
import re
import sqlite3
import logging
import random
import requests
import time  # <-- Add this import
from datetime import datetime, timedelta, timezone
from dotenv import load_dotenv
import spotipy
from spotipy.oauth2 import SpotifyOAuth
from rapidfuzz import fuzz
from typing import List, Dict, Tuple, Optional

# Modify the sys.path to include the project root
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
sys.path.insert(0, project_root)

from src.utils import normalize_string, get_user_input_with_timeout

# Load environment variables
load_dotenv()

# Last.fm API credentials
LASTFM_API_KEY = os.getenv('LASTFM_API_KEY')
LASTFM_USER = os.getenv('LASTFM_USER')

# Spotify API credentials
SPOTIFY_CLIENT_ID = os.getenv('SPOTIFY_CLIENT_ID')
SPOTIFY_CLIENT_SECRET = os.getenv('SPOTIFY_CLIENT_SECRET')
SPOTIFY_REDIRECT_URI = os.getenv('SPOTIPY_REDIRECT_URI')

# Database file paths
LASTFM_100_DAYS_DB = 'db/lastfm_100_days.db'

# Playlist settings
DEFAULT_PLAYLIST_NAME = "Bobby's Hot 💯"
PLAYLIST_ID_FILE = 'playlist_id.txt'
DEFAULT_TIME_RANGE_DAYS = 100
DEFAULT_TRACK_LIMIT = 100

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    filename='logs/hot_100_playlist.log',
    filemode='a'
)
console = logging.StreamHandler()
console.setLevel(logging.INFO)
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
console.setFormatter(formatter)
logging.getLogger('').addHandler(console)

class LastFM100DaysDB:
    def __init__(self, db_file: str):
        self.db_file = db_file
        self.create_table()

    def create_table(self) -> None:
        with sqlite3.connect(self.db_file) as conn:
            c = conn.cursor()
            c.execute('''CREATE TABLE IF NOT EXISTS tracks
                         (id INTEGER PRIMARY KEY AUTOINCREMENT,
                          artist TEXT,
                          name TEXT,
                          album TEXT,
                          play_count INTEGER,
                          last_played TEXT,
                          UNIQUE(artist, name, album))''')
            conn.commit()
        logging.info("Initialized tracks table in Last.fm 100 Days database.")

    def update_tracks(self, tracks: List[Dict]) -> None:
        with sqlite3.connect(self.db_file) as conn:
            c = conn.cursor()
            # Clear existing data
            c.execute("DELETE FROM tracks")
            for track in tracks:
                c.execute('''INSERT OR REPLACE INTO tracks 
                             (artist, name, album, play_count, last_played)
                             VALUES (?, ?, ?, ?, ?)''',
                          (track['artist'], track['name'], track['album'], 
                           track['play_count'], track['last_played'].isoformat()))
            conn.commit()
        logging.info(f"Updated database with {len(tracks)} tracks.")

    def remove_old_tracks(self, cut_off_date: datetime) -> None:
        with sqlite3.connect(self.db_file) as conn:
            c = conn.cursor()
            cut_off_date_str = cut_off_date.isoformat()
            c.execute("DELETE FROM tracks WHERE last_played < ?", (cut_off_date_str,))
            removed = c.rowcount
            conn.commit()
        logging.info(f"Removed {removed} tracks older than {cut_off_date_str}.")

    def get_all_tracks(self) -> List[Tuple]:
        with sqlite3.connect(self.db_file) as conn:
            c = conn.cursor()
            c.execute('''SELECT artist, name, album, play_count FROM tracks
                         ORDER BY play_count DESC, last_played DESC''')
            all_tracks = c.fetchall()
        logging.info(f"Retrieved {len(all_tracks)} tracks from the database.")
        return all_tracks

def get_lastfm_tracks(from_date: datetime, to_date: datetime) -> List[Dict]:
    url = 'http://ws.audioscrobbler.com/2.0/'
    params = {
        'method': 'user.getrecenttracks',
        'user': LASTFM_USER,
        'api_key': LASTFM_API_KEY,
        'format': 'json',
        'limit': 200,
        'from': int(from_date.timestamp()),
        'to': int(to_date.timestamp())
    }

    all_tracks = []
    page = 1

    logging.info("Starting to fetch tracks from Last.fm...")

    while True:
        params['page'] = page
        try:
            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()
            data = response.json()

            if 'error' in data:
                logging.error(f"Error fetching Last.fm tracks: {data['message']}")
                break

            tracks = data['recenttracks']['track']
            if not isinstance(tracks, list):
                tracks = [tracks]
            all_tracks.extend(tracks)

            total_pages = int(data['recenttracks']['@attr']['totalPages'])
            logging.info(f"Fetched page {page} of {total_pages} ({len(tracks)} tracks)")

            if page >= total_pages:
                break
            page += 1
            time.sleep(0.2)  # Sleep to respect API rate limits

        except requests.RequestException as e:
            logging.error(f"Network error when fetching Last.fm tracks: {e}")
            time.sleep(5)
            continue  # Retry on network errors
        except Exception as e:
            logging.error(f"Unexpected error in get_lastfm_tracks: {e}", exc_info=True)
            break

    logging.info(f"Fetched a total of {len(all_tracks)} tracks from Last.fm")
    return all_tracks

def process_lastfm_tracks(tracks: List[Dict]) -> List[Dict]:
    processed_tracks = {}
    now = datetime.now(timezone.utc)

    logging.info("Processing Last.fm tracks...")

    for track in tracks:
        try:
            if 'date' not in track:
                continue  # Skip currently playing track

            artist = track['artist']['#text']
            name = track['name']
            album = track['album']['#text'] if track['album']['#text'] else 'Unknown Album'
            date = datetime.fromtimestamp(int(track['date']['uts']), tz=timezone.utc)

            if (now - date).days > DEFAULT_TIME_RANGE_DAYS:
                continue

            key = (artist.lower(), name.lower(), album.lower())
            if key in processed_tracks:
                processed_tracks[key]['play_count'] += 1
                processed_tracks[key]['last_played'] = max(processed_tracks[key]['last_played'], date)
            else:
                processed_tracks[key] = {
                    'artist': artist,
                    'name': name,
                    'album': album,
                    'play_count': 1,
                    'last_played': date
                }
        except Exception as e:
            logging.error(f"Error processing track: {track}", exc_info=True)
            continue

    logging.info(f"Processed {len(processed_tracks)} unique tracks.")
    return list(processed_tracks.values())

def get_or_create_playlist(sp: spotipy.Spotify, name: str) -> str:
    playlist_id_file = PLAYLIST_ID_FILE

    # Check if playlist ID is stored in file
    if os.path.exists(playlist_id_file):
        with open(playlist_id_file, 'r') as f:
            playlist_id = f.read().strip()
        # Verify that the playlist still exists and is accessible
        try:
            playlist = sp.playlist(playlist_id)
            if playlist['name'] == name:
                logging.info(f"Found existing playlist: {playlist['name']}")
                return playlist_id
            else:
                logging.info(f"Updating playlist name to: {name}")
                sp.user_playlist_change_details(sp.me()['id'], playlist_id, name=name)
                return playlist_id
        except spotipy.exceptions.SpotifyException as e:
            logging.warning(f"Playlist ID not valid or playlist not found. Creating new playlist.")

    # Playlist ID not found or invalid, create a new playlist
    logging.info(f"Creating new playlist: {name}")
    user_id = sp.me()['id']
    playlist = sp.user_playlist_create(user_id, name, public=False)
    # Store the new playlist ID
    with open(playlist_id_file, 'w') as f:
        f.write(playlist['id'])
    return playlist['id']

def update_playlist(sp: spotipy.Spotify, playlist_id: str, track_ids: List[str]) -> None:
    logging.info(f"Updating playlist {playlist_id} with {len(track_ids)} tracks")

    # Randomize the order of tracks
    random.shuffle(track_ids)

    # Clear the playlist first
    sp.playlist_replace_items(playlist_id, [])
    # Spotify API allows up to 100 tracks per request
    for i in range(0, len(track_ids), 100):
        batch = track_ids[i:i+100]
        sp.playlist_add_items(playlist_id, batch)
        logging.info(f"Added {len(batch)} tracks to playlist")
        time.sleep(0.2)  # Sleep to respect API rate limits

    logging.info("Playlist update completed with randomized order")

def main():
    try:
        # Prompt the user for playlist name and time range
        playlist_name = DEFAULT_PLAYLIST_NAME
        time_range_days = DEFAULT_TIME_RANGE_DAYS
        track_limit = DEFAULT_TRACK_LIMIT

        # Initialize Spotify client
        sp = spotipy.Spotify(auth_manager=SpotifyOAuth(scope="playlist-modify-private,playlist-modify-public"))

        # Initialize Last.fm database
        lastfm_db = LastFM100DaysDB(LASTFM_100_DAYS_DB)

        # Calculate date range
        end_date = datetime.utcnow().replace(tzinfo=timezone.utc)
        start_date = end_date - timedelta(days=time_range_days)

        # Fetch Last.fm tracks
        lastfm_tracks = get_lastfm_tracks(start_date, end_date)
        processed_tracks = process_lastfm_tracks(lastfm_tracks)

        # Update database
        lastfm_db.update_tracks(processed_tracks)
        lastfm_db.remove_old_tracks(start_date)

        # Get all tracks sorted by play count descending
        all_tracks = lastfm_db.get_all_tracks()

        # Build a dictionary to keep track of the highest play count for each track
        track_dict = {}
        for artist, name, album, play_count in all_tracks:
            key = (normalize_string(artist), normalize_string(name))
            if key not in track_dict or play_count > track_dict[key]['play_count']:
                track_dict[key] = {
                    'artist': artist,
                    'name': name,
                    'album': album,
                    'play_count': play_count
                }

        # Get the top tracks based on play count
        sorted_tracks = sorted(track_dict.values(), key=lambda x: x['play_count'], reverse=True)

        # Build the list of tracks to add to the playlist
        spotify_track_ids = []
        track_count = 0
        for track_info in sorted_tracks:
            if track_count >= track_limit:
                break

            artist = track_info['artist']
            name = track_info['name']
            album = track_info['album']
            play_count = track_info['play_count']

            logging.info(f"Searching for track: {artist} - {name} (Album: {album}, Play count: {play_count})")

            # Search for the track on Spotify using fuzzy matching
            query = f"track:{name} artist:{artist}"
            try:
                results = sp.search(q=query, type='track', limit=10)
                best_match_id = None
                highest_score = 0
                for item in results['tracks']['items']:
                    spotify_artist = item['artists'][0]['name']
                    spotify_name = item['name']
                    artist_score = fuzz.token_sort_ratio(normalize_string(artist), normalize_string(spotify_artist))
                    name_score = fuzz.token_sort_ratio(normalize_string(name), normalize_string(spotify_name))
                    total_score = (artist_score + name_score) / 2
                    if total_score > highest_score:
                        highest_score = total_score
                        best_match_id = item['id']
                if highest_score > 80 and best_match_id:
                    spotify_track_ids.append(best_match_id)
                    track_count += 1
                    logging.info(f"Found match with score {highest_score}: {spotify_artist} - {spotify_name}")
                else:
                    logging.warning(f"No suitable match found for: {artist} - {name}")
            except Exception as e:
                logging.error(f"Error searching for track on Spotify: {e}", exc_info=True)
                continue

        # Ensure we only have the desired number of tracks
        spotify_track_ids = spotify_track_ids[:track_limit]

        # Get or create playlist
        playlist_id = get_or_create_playlist(sp, playlist_name)

        # Update playlist with randomized order
        update_playlist(sp, playlist_id, spotify_track_ids)

        logging.info(f"Playlist '{playlist_name}' updated with {len(spotify_track_ids)} tracks in random order.")

        # Get the playlist link
        playlist_info = sp.playlist(playlist_id)
        playlist_link = playlist_info['external_urls']['spotify']

        print(f"\nPlaylist updated successfully!")
        print(f"You can access your playlist '{playlist_name}' here: {playlist_link}")
        logging.info(f"Playlist link: {playlist_link}")

    except Exception as e:
        logging.error(f"An unexpected error occurred: {e}", exc_info=True)
        sys.exit(1)

if __name__ == "__main__":
    main()


